{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b438be15-773a-4be0-ad20-839b3b31836a",
   "metadata": {},
   "source": [
    "# JSALT 2025 - Introduction to Large Audio Language Models\n",
    "\n",
    "**Laboratory session: AuGI - Towards audio general intelligence**\n",
    "\n",
    "June 20th, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a4d29-8945-4aa5-97f7-86ff31fa415e",
   "metadata": {},
   "source": [
    "## Introduction and Objectives\n",
    "\n",
    "1. Setting up the Environment\n",
    "2. Exploring Audio Flamingo 2\n",
    "3. Exploring MMAU\n",
    "4. Preparing AQA data\n",
    "5. Simple training/fine-tuning\n",
    "\n",
    "\n",
    "## Materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce8ecb-8403-4fb3-8e0c-f9cf3ed7eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local\n",
    "%cd ..\n",
    "\n",
    "# Remote\n",
    "#!git clone https://github.com/ferugit/JSALT-LALMs-tutorial.git\n",
    "#%cd JSALT-LALMs-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58aa91-aef6-47ef-902a-af1b1145a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbbeff3-db07-4937-aa39-2132a0129ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Qwen2.5-0.5B model\n",
    "!./download_hf_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e7be6-ddf5-48cd-8c96-4f5b4e358965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download AF2 model: CLAP encoder, Audio Transformer and XATTN\n",
    "!./download_af2.sh \"YOUR_HF_TOKEN_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e5af81-9d80-4c65-bad6-9f43a5d3f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat run_af2_single_inference.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161958df-4f41-4eb6-9e20-57652024cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat src/audio_flamingo_2/config/inference.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32d9a9-7037-4dbc-98cd-0748edbe75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run_af2_single_inference.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf4bc9-01e0-49e9-ab33-304ea7b73bcf",
   "metadata": {},
   "source": [
    "# CLAP: Audio Encoder\n",
    "\n",
    "![CLAP Architecture](../assets/clap-arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e6847-02ab-47da-806f-9e9709d0e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import umap\n",
    "import IPython\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "\n",
    "#from src.audio_flamingo_2.my_laion_clap.CLAP.src import laion_clap as local_clap\n",
    "import laion_clap\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2aacc3-734b-4a0d-9a21-c3a504e16ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model = laion_clap.CLAP_Module(enable_fusion=False)\n",
    "model.load_ckpt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438a0fa-9d2e-4d15-9957-e665d72eabe0",
   "metadata": {},
   "source": [
    "## Zero-shot classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f25abf2-54df-430d-a964-f480b73a2e49",
   "metadata": {},
   "source": [
    "![CLAP Architecture](../assets/zero-shot_classification.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c5db3-3118-41bf-9c7a-f102aa85a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's listen some audios\n",
    "cat_filename = \"assets/cat.wav\"\n",
    "dog_filename = \"assets/dog_barking.wav\"\n",
    "another_dog_filename = \"assets/dog.wav\"\n",
    "breaking_filename = \"assets/breaking.wav\"\n",
    "cough_filename = \"assets/cough.wav\"\n",
    "music_filename = \"assets/dance_matisse_musiclm.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b9dfc7-1b23-47bf-87c5-22929eb59bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(cat_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231e34e4-fcd7-4854-84e7-a44a98954b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(dog_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c5a410-f017-4d80-95ff-bd8a3c773f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get audio embeddings from audio files\n",
    "audio_file = [cat_filename, dog_filename]\n",
    "with torch.no_grad():\n",
    "    audio_embed = model.get_audio_embedding_from_filelist(x = audio_file, use_tensor=True)\n",
    "print(audio_embed[:,-20:])\n",
    "print(audio_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33308745-fd61-4f4e-9da0-3e539e8df6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text embedings from texts\n",
    "text_data = [\"This is a sound of a dog\", \"This is a sound of a cat\"] \n",
    "with torch.no_grad():\n",
    "    text_embed = model.get_text_embedding(text_data, use_tensor=True)\n",
    "print(text_embed[:,-20:])\n",
    "print(text_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b552259-a0cd-4945-970b-550bf0129409",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = audio_embed @ text_embed.t()\n",
    "print(\"Similarity matrix:\\n\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368994d-a500-4289-be23-b5d9c752ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate embeddings\n",
    "embeddings = torch.cat([audio_embed, text_embed], dim=0).cpu().numpy()\n",
    "labels = ['audio_cat', 'audio_dog', 'text_dog', 'text_cat']\n",
    "\n",
    "# Solve UMAP 2D projection\n",
    "reducer = umap.UMAP(n_neighbors=2, random_state=1)\n",
    "embeddings_2d = reducer.fit_transform(embeddings)\n",
    "\n",
    "# Plot emdedding distances\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1], label=label)\n",
    "    plt.text(embeddings_2d[i, 0]+0.01, embeddings_2d[i, 1]+0.01, label)\n",
    "\n",
    "# Draw lines between audio and text pairs to show distances\n",
    "plt.plot([embeddings_2d[0, 0], embeddings_2d[3, 0]], [embeddings_2d[0, 1], embeddings_2d[3, 1]], 'r--', label='cat distance')\n",
    "plt.plot([embeddings_2d[1, 0], embeddings_2d[2, 0]], [embeddings_2d[1, 1], embeddings_2d[2, 1]], 'b--', label='dog distance')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('2D Visualization of Audio and Text Embeddings with Distances')\n",
    "plt.xlabel('UMAP-1')\n",
    "plt.ylabel('UMAP-2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d3e4b3-926e-4ee3-a901-a83f4edddbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity\n",
    "cos_sim = torch.nn.CosineSimilarity(dim=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264f14f-ff8a-4b59-a910-fc313ff0d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cacluclate cosine distance\n",
    "audio_file = [dog_filename]\n",
    "with torch.no_grad():\n",
    "    audio_embed = model.get_audio_embedding_from_filelist(x = audio_file, use_tensor=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_embed = model.get_text_embedding(\"This is a dog barking\", use_tensor=True)\n",
    "\n",
    "similarity = cos_sim(audio_embed[-1], text_embed[-1])\n",
    "distance = 1 - similarity\n",
    "print(\"Cosine Distance:\", distance.item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f90a5-1ecb-419e-aa3f-de88fbb7bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(cough_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e7ea48-9c30-4270-87cb-cff5a2578311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cacluclate cosine distance\n",
    "audio_file = [cough_filename]\n",
    "with torch.no_grad():\n",
    "    audio_embed = model.get_audio_embedding_from_filelist(x = audio_file, use_tensor=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_embed = model.get_text_embedding(\"This is a dog barking\", use_tensor=True)\n",
    "\n",
    "similarity = cos_sim(audio_embed[-1], text_embed[-1])\n",
    "distance = 1 - similarity\n",
    "print(\"Cosine Distance:\", distance.item()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95e4c8-3bc9-4a19-89fe-6b3521f626d2",
   "metadata": {},
   "source": [
    "# Audio Flamingo 2\n",
    "\n",
    "![AF2 Architecture](../assets/af2_arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d420aa5-8aba-4d84-b746-d3745e9702fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat src/audio_flamingo_2/config/inference.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6de94-c53e-45da-94de-ffc2a6d62be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat run_af2_single_inference.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f1039-0f53-42b1-8917-e497900dc996",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run_af2_single_inference.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
